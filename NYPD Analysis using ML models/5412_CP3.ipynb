{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font face=\"Arial\" color=\"dodgerblue\" size=6><b>Coding Practice 3</b></font>\n",
        "\n",
        "<hr color=\"dodgerblue\">\n",
        "\n",
        "> <font face=\"Times New Roman\" size=5>Probabilistic language models from scratch\n",
        "\n"
      ],
      "metadata": {
        "id": "LYMXeWz6lERR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsEFPba0lBpD",
        "outputId": "b1fc8809-2764-4b99-d725-f88010139b55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# download some corpora\n",
        "nltk.download([\"brown\", \"webtext\", \"treebank\"])\n",
        "\n",
        "# import some useful functions\n",
        "from nltk import FreqDist, ConditionalFreqDist, bigrams, trigrams\n",
        "\n",
        "# load the corpora\n",
        "from nltk.corpus import brown, webtext as chat, treebank as wsj"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font size=5 color=\"darkblue\" face=\"Arial\">**Part 1**</font>\n",
        "\n",
        "<hr color=\"darkblue\">\n",
        "\n",
        "> <font face=\"Times New Roman\" size=5>Obtaining and normalizing training texts\n",
        "\n",
        "You will need\n",
        "- a function to pad each sentence with start symbol \"\\<s>\" and stop symbol \"\\</s>\"\n",
        "\n",
        "- a function to flatten the list of padded sentences into individual words and normalize to lowercase\n",
        "\n",
        "\n",
        "Below you will find examples of two useful functions:\n",
        "  - `nltk.pad_sequence()`: adds start/end symbols to lists of words\n",
        "  - `nltk.flatten()`: flattens lists of lists into single-level lists\n"
      ],
      "metadata": {
        "id": "McNENOV1rgEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import flatten, pad_sequence"
      ],
      "metadata": {
        "id": "KmN4t5rKoxni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example of `pad_sequence`"
      ],
      "metadata": {
        "id": "Rd3ng5b6qgaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First two sentences from the first file of Brown corpus\n",
        "brown_first_file = brown.fileids()[0] # get the name of the first file\n",
        "brown_first_2sents = brown.sents(brown_first_file)[:2] # pull the first two sentences from the first file\n",
        "sample_sents = list(brown_first_2sents) # list to extract values from generator"
      ],
      "metadata": {
        "id": "IYalioQIqndz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the two Brown sentences, and prove that this is a list of list (length 2)\n",
        "print(sample_sents[0])\n",
        "print(sample_sents[1])\n",
        "\n",
        "print(type(sample_sents[0]))\n",
        "print(type(sample_sents[1]))\n",
        "print(len(sample_sents))"
      ],
      "metadata": {
        "id": "52W7C7h8pJ5W",
        "outputId": "303b754a-19b0-4453-fe66-591f4767fe58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
            "['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']\n",
            "<class 'list'>\n",
            "<class 'list'>\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad a single sentence\n",
        "# - the first arg = the sentence to pad\n",
        "# - the second arg = the n-gram size of your model (>=2; 2=bigram, 3=trigram, ...)\n",
        "# - do you want padding on the left and/or right edge of the list?\n",
        "# - what symbol do you want to use for padding?\n",
        "padded = list(pad_sequence(sample_sents[0], 2, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol = \"</s>\"))\n",
        "print(len(padded))\n",
        "print(len(sample_sents[0]))\n",
        "print(padded)"
      ],
      "metadata": {
        "id": "1nRG0TJDqyhR",
        "outputId": "32c7adfe-4118-4404-8d2b-af233385d485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "25\n",
            "['<s>', 'The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example of `flatten`\n",
        "  - function to turn lists of lists into single-level lists"
      ],
      "metadata": {
        "id": "BF6FuXMDqZYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now flatten\n",
        "flat = flatten(sample_sents)\n",
        "\n",
        "print(len(flat)) # 68 total words; achieved by turning a list of lists into a list of strings (flattening)\n",
        "print(len(sample_sents[0]) + len(sample_sents[1])) # same as the sum of the lengths of the embedded lists in the non-flattended version"
      ],
      "metadata": {
        "id": "0CWfBRqnpWMb",
        "outputId": "40af0c69-094a-4695-99ce-00f6f7a2cfab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68\n",
            "68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will need to integrate these functions together to create a single of list of words + pads."
      ],
      "metadata": {
        "id": "ns5Ip5c6tMYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font size=5 color=\"darkblue\" face=\"Arial\">**Part 2**</font>\n",
        "\n",
        "<hr color=\"darkblue\">\n",
        "\n",
        "> <font face=\"Times New Roman\" size=5>Generating Frequency Distributions for unigram, bigram, and trigram models"
      ],
      "metadata": {
        "id": "uaxTETBWqUJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some tips:\n",
        "- bigram and trigram models need padding\n",
        "  - bigram: each sentence should begin with an inserted \"\\<s>\" symbol\n",
        "  - trigram: each sentences should begin with an inserted \"\\<s> \\<s>\" sequence\n",
        "- **unigram models** use $p(\\text{word})$ only\n",
        "- **bigram models** use $p(w_i|w_{i-1})$\n",
        "- **trigram models** use $p(w_i|w_{i-2}, w_{i-1})$\n",
        "- `FreqDist`\n",
        "  - takes a list (of words) and counts the number of occurrences of each type (word type)\n",
        "  - returns a dictionary-like object: keys are words and values are frequencies\n",
        "- `ConditionalFreqDist`\n",
        "  - takes a list of tuples `(x, y)` and counts the joint frequencies\n",
        "  - returns a dictionary-like object: keys are `x` types and values are `FreqDist`of the `y` types\n"
      ],
      "metadata": {
        "id": "lfT57ilQQlxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examples for computing FreqDist and ConditionalFreqDist objects"
      ],
      "metadata": {
        "id": "TcckBeTUtn4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigram example\n",
        "uni_list = list([\"a\"]*10 + [\"b\"]*20 + [\"c\"]*5)\n",
        "\n",
        "uni_fd = FreqDist(uni_list)\n",
        "uni_fd"
      ],
      "metadata": {
        "id": "d1ikfRHUS9Tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c61ab2-6327-457e-bff4-2527bf1a1f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'b': 20, 'a': 10, 'c': 5})"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(uni_fd['a'])"
      ],
      "metadata": {
        "id": "wrEXbyf5TXbY",
        "outputId": "d9f8b7af-1a17-40c7-ab62-ef8376b9b70e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(uni_fd['b'])"
      ],
      "metadata": {
        "id": "qp36X7cFTZoP",
        "outputId": "5acb63e4-6421-41e3-9c8b-8db735f43bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(uni_fd['c'])"
      ],
      "metadata": {
        "id": "TrXp-q1XTblT",
        "outputId": "25a67d7a-a33b-4566-a22f-1d90ba2ee71c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bigram example\n",
        "bi_list = bigrams(uni_list)\n",
        "\n",
        "bi_cfd = ConditionalFreqDist(bi_list)\n",
        "bi_cfd"
      ],
      "metadata": {
        "id": "Eynyic_yULUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339056a2-8a73-4717-e4a9-86cf13995519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ConditionalFreqDist with 3 conditions>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_cfd['a']"
      ],
      "metadata": {
        "id": "DrXJWfNxUaqZ",
        "outputId": "dcd1b940-e043-4cee-f837-9a03a5fd4011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'a': 9, 'b': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_cfd['b']"
      ],
      "metadata": {
        "id": "RN78SbU0U6It",
        "outputId": "b3cb2635-f7dc-4bd9-a7ce-64e1fcb15bbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'b': 19, 'c': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_cfd['c']"
      ],
      "metadata": {
        "id": "Gw4tcc72U_L2",
        "outputId": "66c70193-348a-4bb7-9169-1c4e7f30bb95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'c': 4})"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigram example\n",
        "tri_list = trigrams(uni_list)\n",
        "\n",
        "# ... we need to make a small change to the trigrams\n",
        "tri_list = [((t1, t2), t3) for t1, t2, t3 in tri_list]"
      ],
      "metadata": {
        "id": "NWajr3tVVF7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tri_cfd = ConditionalFreqDist(tri_list)"
      ],
      "metadata": {
        "id": "nR9sT1LsVISG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tri_cfd[('a', 'a')]"
      ],
      "metadata": {
        "id": "yKLgjvqeVwnQ",
        "outputId": "c8604c16-9507-49d8-8479-722d33b7a0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'a': 8, 'b': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The lists that you feed the FreqDist/ConditionalFreqDist functions should be appropriately padded and normalized.**"
      ],
      "metadata": {
        "id": "gktXxLDEtwFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Your **unigram model** corresponds to the `FreqDist` of the (padded, normalized, and flattened) text"
      ],
      "metadata": {
        "id": "Tc0DxUY5vCqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigram models (enter your answer here)\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "## for `chat`\n",
        "chat_uni_list = list(pad_sequence([word for sentence in chat.sents() for word in sentence], 1, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "chat_uni_fd = FreqDist(chat_uni_list)\n",
        "\n",
        "\n",
        "## for `brown`\n",
        "brown_uni_list = list(pad_sequence([word for sentence in brown.sents() for word in sentence], 1, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "brown_uni_fd = FreqDist(brown_uni_list)\n",
        "\n",
        "## for `treebank`\n",
        "treebank_uni_list = list(pad_sequence([word for sentence in wsj.sents() for word in sentence], 1, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "treebank_uni_fd = FreqDist(treebank_uni_list)"
      ],
      "metadata": {
        "id": "j5pynGqauGow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b65b61-d733-410b-a653-3f8d78a76d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. Your **bigram model** corresponds to the `ConditionalFreqDist` over the output of `bigrams` applied to the (padded, normalized, and flattened) text"
      ],
      "metadata": {
        "id": "l1kUK1PxvkXu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3tp8Oa22A1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bigram models (enter your answer here)\n",
        "\n",
        "## for `chat`\n",
        "chat_bi_list = bigrams(pad_sequence([word for sentence in chat.sents() for word in sentence], 2, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "chat_bi_cfd = ConditionalFreqDist(chat_bi_list)\n",
        "\n",
        "## for `brown`\n",
        "brown_bi_list = bigrams(pad_sequence([word for sentence in brown.sents() for word in sentence], 2, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "brown_bi_cfd = ConditionalFreqDist(brown_bi_list)\n",
        "\n",
        "## for `treebank`\n",
        "treebank_bi_list = bigrams(pad_sequence([word for sentence in wsj.sents() for word in sentence], 2, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "treebank_bi_cfd = ConditionalFreqDist(treebank_bi_list)"
      ],
      "metadata": {
        "id": "r0DZl8vXuIKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c. Your **trigram model** corresponds to the `ConditionalFreqDist` of the output of `trigrams` appropriately altered as outlined above (e.g., to create a list of the form `[((word_1, word_2), word_3), ...]`)"
      ],
      "metadata": {
        "id": "DJBO4tZFv0w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigram models (enter your answer here)\n",
        "\n",
        "## for `chat`\n",
        "chat_tri_list = trigrams(pad_sequence([word for sentence in chat.sents() for word in sentence], 3, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "chat_tri_list = [((t1, t2), t3) for t1, t2, t3 in chat_tri_list]\n",
        "chat_tri_cfd = ConditionalFreqDist(chat_tri_list)\n",
        "\n",
        "## for `brown`\n",
        "brown_tri_list = trigrams(pad_sequence([word for sentence in brown.sents() for word in sentence], 3, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "brown_tri_list = [((t1, t2), t3) for t1, t2, t3 in brown_tri_list]\n",
        "brown_tri_cfd = ConditionalFreqDist(brown_tri_list)\n",
        "\n",
        "## for `treebank`\n",
        "treebank_tri_list = trigrams(pad_sequence([word for sentence in wsj.sents() for word in sentence], 3, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "treebank_tri_list = [((t1, t2), t3) for t1, t2, t3 in treebank_tri_list]\n",
        "treebank_tri_cfd = ConditionalFreqDist(treebank_tri_list)"
      ],
      "metadata": {
        "id": "NbJaoCuLuM4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font size=5 color=\"darkblue\" face=\"Arial\">**Part 3**</font>\n",
        "\n",
        "<hr color=\"darkblue\">\n",
        "\n",
        "> <font face=\"Times New Roman\" size=5>Assessing *n*-gram model fits and generalizability\n",
        "\n",
        "To estimate the fit of an *n*-gram model, we test how likely it considers known grammatical sentences to be, based on how much memory the system has.\n",
        "\n",
        "A bigram model remembers just the immediately prior word, while the trigram model remembers the joint presence of the immediately prior *two* words.\n",
        "\n",
        "Simplifying, we assume proportionality between the true joint probability of the words in a sentence and the product of the individual transitions (conditional probabilities) within the sentence (the **Markov assumption**).\n",
        "\n",
        "For a three word sentence like \"The cat slept\" (with padding for bigrams):\n",
        "\n",
        "$$p(\\text{<s>}, the, cat, slept, \\text{</s>}) \\propto p(the|\\text{<s>} * p(cat | the) * p(slept|cat) * p(\\text{</s>}|slept)$$\n",
        "\n",
        "i.e., each choice of transition is statistically independent from the last."
      ],
      "metadata": {
        "id": "iWBDP9tHd394"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. Write a function to apply Laplace smoothing to unseen tokens\n",
        "---\n",
        "\n",
        "If your test data have words or *n*-grams that it has not seen during training, we want to still compute a probability > 0.\n",
        "\n",
        "Laplace smoothing adds 1 (a special case of add-*K* systems) to each unobserved and observed frequency.\n",
        "\n",
        "$$count_{Laplace}{x} = \\frac{count(x) + 1}{\\sum_i{count(x_i}) + V},$$\n",
        "\n",
        "where $V$ is the vocabulary size, or `len(list(vocab)` based on the example code above.\n",
        "\n",
        "---\n",
        "\n",
        "So, the Laplace smoother will be applied to observed and unobserved tokens alike."
      ],
      "metadata": {
        "id": "5mGdIxGByBYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Laplace function\n",
        "\n",
        "def laplace(count, total_count, vocab_size):\n",
        "    if total_count == 0:\n",
        "        return 1 / (vocab_size+1)\n",
        "    else:\n",
        "        return (count + 1) / (total_count + vocab_size)"
      ],
      "metadata": {
        "id": "3ssVz4uA9orT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using your Laplace smoothing function, compute the Markov likelihood and perplexity of the following sentences given your unigram, bigram, and trigram models.\n",
        "\n",
        "**Extra challenge**:<br>\n",
        "**To get the perplexity, raise each product to $-1/N$ where $N$ is the sample size**\n",
        "\n",
        "$$ Perplexity = \\prod{p(w_i|...)}^{-1/N)}$$\n",
        "\n",
        "- $N$ can be computed from FreqDist or ConditionalFreqDist objects as `.N()`\n",
        "\n",
        "You can find more info here: https://www.nltk.org/api/nltk.probability.FreqDist.html"
      ],
      "metadata": {
        "id": "TFzXkhPY-zIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The company declared bankruptcy\n",
        "sentences = [\"The company declared bankruptcy\"]\n",
        "\n",
        "## unigrams (enter responses below)\n",
        "def unigram(sentences,lst,fd):\n",
        "  for word in sentences:\n",
        "    sentence_tokens = [\"<s>\"] + word.lower().split() + [\"</s>\"]\n",
        "    uni_prob = 1\n",
        "    for token in sentence_tokens:\n",
        "        uni_prob *= laplace(fd[token], len(lst), len(fd))\n",
        "    uni_perplexity = pow(uni_prob, -1 / len(sentence_tokens))\n",
        "    print(\"Sentence:\", word)\n",
        "    print(\"Unigram Perplexity:\", uni_perplexity)\n",
        "\n",
        "### Chat\n",
        "unigram(sentences,chat_uni_list,chat_uni_fd)\n",
        "\n",
        "### Brown\n",
        "unigram(sentences,brown_uni_list,brown_uni_fd)\n",
        "\n",
        "### Treebank\n",
        "unigram(sentences,treebank_uni_list,treebank_uni_fd)\n",
        "\n",
        "\n",
        "\n",
        "## bigram (enter responses below)\n",
        "def bigram(sentences,fd):\n",
        "  for word in sentences:\n",
        "    sentence_tokens = [\"<s>\"] + word.lower().split() + [\"</s>\"]\n",
        "    bi_prob = 1\n",
        "    for t1, t2 in zip(sentence_tokens, sentence_tokens[1:]):\n",
        "        bi_prob *= laplace(fd[t1].freq(t2), fd[t1].N(), len(fd[t1]))\n",
        "    bi_perplexity = pow(bi_prob, -1 / (len(sentence_tokens) - 1))\n",
        "    print(\"Sentence:\", word)\n",
        "    print(\"Bigram Perplexity:\", bi_perplexity)\n",
        "\n",
        "### Chat\n",
        "bigram(sentences,chat_bi_cfd)\n",
        "\n",
        "### Brown\n",
        "bigram(sentences,brown_bi_cfd)\n",
        "\n",
        "### Treebank\n",
        "bigram(sentences,treebank_bi_cfd)\n",
        "\n",
        "\n",
        "\n",
        "## trigram (enter responses below)\n",
        "def trigram(sentences,fd):\n",
        "  for sentence in sentences:\n",
        "      sentence_tokens = [\"<s>\"] + sentence.lower().split() + [\"</s>\"]\n",
        "      tri_prob = 1\n",
        "      for (t1, t2), t3 in zip(zip(sentence_tokens, sentence_tokens[1:]), sentence_tokens[2:]):\n",
        "          tri_prob *= laplace(fd[(t1, t2)].freq(t3), fd[(t1, t2)].N(), len(fd[(t1, t2)]))\n",
        "      tri_perplexity = pow(tri_prob, -1 / (len(sentence_tokens) - 2))\n",
        "\n",
        "### Chat\n",
        "trigram(sentences,chat_tri_cfd)\n",
        "### Brown\n",
        "trigram(sentences,brown_tri_cfd)\n",
        "\n",
        "### Treebank\n",
        "trigram(sentences,treebank_tri_cfd)\n"
      ],
      "metadata": {
        "id": "a49gUQAs-xeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd1893a-e5cb-4fd9-c15d-2efce1171aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: The company declared bankruptcy\n",
            "Unigram Perplexity: 55897.705070214455\n",
            "Sentence: The company declared bankruptcy\n",
            "Unigram Perplexity: 27061.909561003424\n",
            "Sentence: The company declared bankruptcy\n",
            "Unigram Perplexity: 5663.673674925953\n",
            "Sentence: The company declared bankruptcy\n",
            "Bigram Perplexity: 15.36967956951486\n",
            "Sentence: The company declared bankruptcy\n",
            "Bigram Perplexity: 149.6362040720315\n",
            "Sentence: The company declared bankruptcy\n",
            "Bigram Perplexity: 53.80531025243895\n"
          ]
        }
      ]
    }
  ]
}